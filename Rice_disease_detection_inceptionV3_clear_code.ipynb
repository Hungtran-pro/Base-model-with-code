{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rice_disease_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4Xkw5PB_3LkB"
      ],
      "mount_file_id": "1cFdRQvtzgELkTykTAG9WWc0_ZGF8r48b",
      "authorship_tag": "ABX9TyN0FwPJRS9JKzeeBEjMZJUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hungtran-pro/codeCoursera/blob/main/Rice_disease_detection_inceptionV3_clear_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load libraries"
      ],
      "metadata": {
        "id": "z1hZ_upk0jS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from __future__ import absolute_import, division, print_function\n",
        "import math"
      ],
      "metadata": {
        "id": "uUTV6o3Jy-M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelled_path = '/content/drive/MyDrive/AI projects/Disease of rice/Labelled'\n",
        "train_validate_path = '/content/drive/MyDrive/AI projects/Disease of rice/RiceDiseaseDataset'"
      ],
      "metadata": {
        "id": "jiFo6O9_zKXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = (train_validate_path + '/train/BrownSpot/IMG_20190419_095712.jpg')\n",
        "img = cv2.imread(temp)\n",
        "dimensions = img.shape"
      ],
      "metadata": {
        "id": "dKdgHvEw4Acu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI_yWg0b4szh",
        "outputId": "45e1dccd-d565-4106-9448-8afa71160d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1282, 1282, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "Kjy1S5RO0T6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 8\n",
        "NUM_CLASSES = 4\n",
        "image_height = 300\n",
        "image_width = 300\n",
        "channels = 3\n",
        "save_model_dir = \"/content/drive/MyDrive/AI projects/Disease of rice/saved_model/model\""
      ],
      "metadata": {
        "id": "CviXXIxgP3zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      # rotation_range=40,\n",
        "      # width_shift_range=0.2,\n",
        "      # height_shift_range=0.2,\n",
        "      # shear_range=0.2,\n",
        "      # zoom_range=0.2,\n",
        "      # horizontal_flip=True,\n",
        "      # fill_mode='nearest'\n",
        "      )\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_validate_path + '/train',  # This is the source directory for training images\n",
        "        target_size=(image_height, image_width),  # All images will be resized to 150x150\n",
        "        batch_size=100,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        train_validate_path + '/validation',  # This is the source directory for training images\n",
        "        target_size=(image_height, image_width),  # All images will be resized to 150x150\n",
        "        batch_size=100,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vj4ks3ozgqt",
        "outputId": "db419bd7-2bb5-4b2c-fe99-6fea3dd84058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 4 classes.\n",
            "Found 492 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "4Xkw5PB_3LkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(1282, 1282, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "1OKdWz9AzlDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ym48nUzFzxPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch = 8,  \n",
        "      epochs=EPOCHS,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps = 8)"
      ],
      "metadata": {
        "id": "M9oxMcmazt9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inception Net"
      ],
      "metadata": {
        "id": "l86FxL5c3HXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicConv2D(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, strides, padding):\n",
        "        super(BasicConv2D, self).__init__()\n",
        "        self.conv = tf.keras.layers.Conv2D(filters=filters,\n",
        "                                           kernel_size=kernel_size,\n",
        "                                           strides=strides,\n",
        "                                           padding=padding)\n",
        "        self.bn = tf.keras.layers.BatchNormalization()\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        output = self.conv(inputs)\n",
        "        output = self.bn(output, training=training)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class Preprocess(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Preprocess, self).__init__()\n",
        "        self.conv1 = BasicConv2D(filters=32,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 strides=2,\n",
        "                                 padding=\"same\")\n",
        "        self.conv2 = BasicConv2D(filters=32,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv3 = BasicConv2D(filters=64,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "\n",
        "        self.maxpool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                                  strides=2,\n",
        "                                                  padding=\"same\")\n",
        "        self.conv4 = BasicConv2D(filters=80,\n",
        "                                 kernel_size=(1, 1),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv5 = BasicConv2D(filters=192,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.maxpool2 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                                  strides=2,\n",
        "                                                  padding=\"same\")\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        x = self.conv1(inputs, training=training)\n",
        "        x = self.conv2(x, training=training)\n",
        "        x = self.conv3(x, training=training)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv4(x, training=training)\n",
        "        x = self.conv5(x, training=training)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class InceptionAux(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_classes):\n",
        "        super(InceptionAux, self).__init__()\n",
        "        self.avg_pool = tf.keras.layers.AvgPool2D(pool_size=(5, 5),\n",
        "                                                  strides=3,\n",
        "                                                  padding=\"same\")\n",
        "        self.conv1 = BasicConv2D(filters=128,\n",
        "                                 kernel_size=(1, 1),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv2 = BasicConv2D(filters=768,\n",
        "                                 kernel_size=(5, 5),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.flat = tf.keras.layers.Flatten()\n",
        "        self.fc = tf.keras.layers.Dense(units=num_classes, activation=tf.keras.activations.linear)\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        output = self.avg_pool(inputs)\n",
        "        output = self.conv1(output, training=training)\n",
        "        output = self.conv2(output, training=training)\n",
        "        output = self.global_avg_pool(output)\n",
        "        output = self.flat(output)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class InceptionModule_1(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_num):\n",
        "        super(InceptionModule_1, self).__init__()\n",
        "        # branch 0\n",
        "        self.conv_b0_1 = BasicConv2D(filters=64,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        # branch 1\n",
        "        self.conv_b1_1 = BasicConv2D(filters=48,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        self.conv_b1_2 = BasicConv2D(filters=64,\n",
        "                                     kernel_size=(5, 5),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        # branch 2\n",
        "        self.conv_b2_1 = BasicConv2D(filters=64,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        self.conv_b2_2 = BasicConv2D(filters=96,\n",
        "                                     kernel_size=(3, 3),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b2_3 = BasicConv2D(filters=96,\n",
        "                                     kernel_size=(3, 3),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        # branch 3\n",
        "        self.avgpool_b3_1 = tf.keras.layers.AvgPool2D(pool_size=(3, 3),\n",
        "                                                      strides=1,\n",
        "                                                      padding=\"same\")\n",
        "        self.conv_b3_2 = BasicConv2D(filters=filter_num,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "\n",
        "        b0 = self.conv_b0_1(inputs, training=training)\n",
        "\n",
        "        b1 = self.conv_b1_1(inputs, training=training)\n",
        "        b1 = self.conv_b1_2(b1, training=training)\n",
        "\n",
        "        b2 = self.conv_b2_1(inputs, training=training)\n",
        "        b2 = self.conv_b2_2(b2, training=training)\n",
        "        b2 = self.conv_b2_3(b2, training=training)\n",
        "\n",
        "        b3 = self.avgpool_b3_1(inputs)\n",
        "        b3 = self.conv_b3_2(b3, training=training)\n",
        "\n",
        "        output = tf.keras.layers.concatenate([b0, b1, b2, b3], axis=-1)\n",
        "        return output\n",
        "\n",
        "\n",
        "class InceptionModule_2(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(InceptionModule_2, self).__init__()\n",
        "        # branch 0\n",
        "        self.conv_b0_1 = BasicConv2D(filters=384,\n",
        "                                     kernel_size=(3, 3),\n",
        "                                     strides=2,\n",
        "                                     padding=\"valid\")\n",
        "\n",
        "        # branch 1\n",
        "        self.conv_b1_1 = BasicConv2D(filters=64,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b1_2 = BasicConv2D(filters=96,\n",
        "                                     kernel_size=(3, 3),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b1_3 = BasicConv2D(filters=96,\n",
        "                                     kernel_size=(3, 3),\n",
        "                                     strides=2,\n",
        "                                     padding=\"valid\")\n",
        "\n",
        "        # branch 2\n",
        "        self.maxpool_b2_1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                                      strides=2,\n",
        "                                                      padding=\"valid\")\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        b0 = self.conv_b0_1(inputs, training=training)\n",
        "\n",
        "        b1 = self.conv_b1_1(inputs, training=training)\n",
        "        b1 = self.conv_b1_2(b1, training=training)\n",
        "        b1 = self.conv_b1_3(b1, training=training)\n",
        "\n",
        "        b2 = self.maxpool_b2_1(inputs)\n",
        "\n",
        "        output = tf.keras.layers.concatenate([b0, b1, b2], axis=-1)\n",
        "        return output\n",
        "\n",
        "\n",
        "class InceptionModule_3(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_num):\n",
        "        super(InceptionModule_3, self).__init__()\n",
        "        # branch 0\n",
        "        self.conv_b0_1 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        # branch 1\n",
        "        self.conv_b1_1 = BasicConv2D(filters=filter_num,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b1_2 = BasicConv2D(filters=filter_num,\n",
        "                                     kernel_size=(1, 7),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b1_3 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(7, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        # branch 2\n",
        "        self.conv_b2_1 = BasicConv2D(filters=filter_num,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b2_2 = BasicConv2D(filters=filter_num,\n",
        "                                     kernel_size=(7, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b2_3 = BasicConv2D(filters=filter_num,\n",
        "                                     kernel_size=(1, 7),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b2_4 = BasicConv2D(filters=filter_num,\n",
        "                                     kernel_size=(7, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b2_5 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(1, 7),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        # branch 3\n",
        "        self.avgpool_b3_1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                                      strides=1,\n",
        "                                                      padding=\"same\")\n",
        "        self.conv_b3_2 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        b0 = self.conv_b0_1(inputs, training=training)\n",
        "\n",
        "        b1 = self.conv_b1_1(inputs, training=training)\n",
        "        b1 = self.conv_b1_2(b1, training=training)\n",
        "        b1 = self.conv_b1_3(b1, training=training)\n",
        "\n",
        "        b2 = self.conv_b2_1(inputs, training=training)\n",
        "        b2 = self.conv_b2_2(b2, training=training)\n",
        "        b2 = self.conv_b2_3(b2, training=training)\n",
        "        b2 = self.conv_b2_4(b2, training=training)\n",
        "        b2 = self.conv_b2_5(b2, training=training)\n",
        "\n",
        "        b3 = self.avgpool_b3_1(inputs)\n",
        "        b3 = self.conv_b3_2(b3, training=training)\n",
        "\n",
        "        output = tf.keras.layers.concatenate([b0, b1, b2, b3], axis=-1)\n",
        "        return output\n",
        "\n",
        "\n",
        "class InceptionModule_4(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(InceptionModule_4, self).__init__()\n",
        "        # branch 0\n",
        "        self.conv_b0_1 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "        self.conv_b0_2 = BasicConv2D(filters=320,\n",
        "                                     kernel_size=(3, 3),\n",
        "                                     strides=2,\n",
        "                                     padding=\"valid\")\n",
        "\n",
        "        # branch 1\n",
        "        self.conv_b1_1 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        self.conv_b1_2 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(1, 7),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        self.conv_b1_3 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(7, 1),\n",
        "                                     strides=1,\n",
        "                                     padding=\"same\")\n",
        "\n",
        "        self.conv_b1_4 = BasicConv2D(filters=192,\n",
        "                                     kernel_size=(3, 3),\n",
        "                                     strides=2,\n",
        "                                     padding=\"valid\")\n",
        "\n",
        "\n",
        "        # branch 2\n",
        "        self.maxpool_b2_1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                                      strides=2,\n",
        "                                                      padding=\"valid\")\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        b0 = self.conv_b0_1(inputs, training=training)\n",
        "        b0 = self.conv_b0_2(b0, training=training)\n",
        "\n",
        "        b1 = self.conv_b1_1(inputs, training=training)\n",
        "        b1 = self.conv_b1_2(b1, training=training)\n",
        "        b1 = self.conv_b1_3(b1, training=training)\n",
        "        b1 = self.conv_b1_4(b1, training=training)\n",
        "\n",
        "        b2 = self.maxpool_b2_1(inputs)\n",
        "\n",
        "        output = tf.keras.layers.concatenate([b0, b1, b2], axis=-1)\n",
        "        return output\n",
        "\n",
        "\n",
        "class InceptionModule_5(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(InceptionModule_5, self).__init__()\n",
        "        self.conv1 = BasicConv2D(filters=320,\n",
        "                                 kernel_size=(1, 1),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv2 = BasicConv2D(filters=384,\n",
        "                                 kernel_size=(1, 1),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv3 = BasicConv2D(filters=448,\n",
        "                                 kernel_size=(1, 1),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv4 = BasicConv2D(filters=384,\n",
        "                                 kernel_size=(1, 3),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv5 = BasicConv2D(filters=384,\n",
        "                                 kernel_size=(3, 1),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv6 = BasicConv2D(filters=384,\n",
        "                                 kernel_size=(3, 3),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.conv7 = BasicConv2D(filters=192,\n",
        "                                 kernel_size=(1, 1),\n",
        "                                 strides=1,\n",
        "                                 padding=\"same\")\n",
        "        self.avgpool = tf.keras.layers.AvgPool2D(pool_size=(3, 3),\n",
        "                                                 strides=1,\n",
        "                                                 padding=\"same\")\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        b0 = self.conv1(inputs, training=training)\n",
        "\n",
        "        b1 = self.conv2(inputs, training=training)\n",
        "        b1_part_a = self.conv4(b1, training=training)\n",
        "        b1_part_b = self.conv5(b1, training=training)\n",
        "        b1 = tf.keras.layers.concatenate([b1_part_a, b1_part_b], axis=-1)\n",
        "\n",
        "        b2 = self.conv3(inputs, training=training)\n",
        "        b2 = self.conv6(b2, training=training)\n",
        "        b2_part_a = self.conv4(b2, training=training)\n",
        "        b2_part_b = self.conv5(b2, training=training)\n",
        "        b2 = tf.keras.layers.concatenate([b2_part_a, b2_part_b], axis=-1)\n",
        "        b3 = self.avgpool(inputs)\n",
        "        b3 = self.conv7(b3, training=training)\n",
        "\n",
        "        output = tf.keras.layers.concatenate([b0, b1, b2, b3], axis=-1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "04Pd1smA3Iw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "_InceptionOutputs = namedtuple(\"InceptionOutputs\", [\"logits\", \"aux_logits\"])\n",
        "\n",
        "\n",
        "class InceptionV3(tf.keras.Model):\n",
        "    def __init__(self, num_class, aux_logits=True):\n",
        "        super(InceptionV3, self).__init__()\n",
        "        self.aux_logits = aux_logits\n",
        "        self.preprocess = Preprocess()\n",
        "\n",
        "        self.block_1 = tf.keras.Sequential([\n",
        "            InceptionModule_1(filter_num=32),\n",
        "            InceptionModule_1(filter_num=64),\n",
        "            InceptionModule_1(filter_num=64)\n",
        "        ])\n",
        "\n",
        "        self.block_2 = tf.keras.Sequential([\n",
        "            InceptionModule_2(),\n",
        "            InceptionModule_3(filter_num=128),\n",
        "            InceptionModule_3(filter_num=160),\n",
        "            InceptionModule_3(filter_num=160),\n",
        "            InceptionModule_3(filter_num=192),\n",
        "        ])\n",
        "\n",
        "        if self.aux_logits:\n",
        "            self.AuxLogits = InceptionAux(num_classes=num_class)\n",
        "\n",
        "        self.block_3 = tf.keras.Sequential([\n",
        "            InceptionModule_4(),\n",
        "            InceptionModule_5(),\n",
        "            InceptionModule_5()\n",
        "        ])\n",
        "        self.avg_pool = tf.keras.layers.AvgPool2D(pool_size=(8, 8),\n",
        "                                                  strides=1,\n",
        "                                                  padding=\"valid\")\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=0.2)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc = tf.keras.layers.Dense(units=num_class, activation=tf.keras.activations.linear)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None, include_aux_logits=True):\n",
        "        x = self.preprocess(inputs, training=training)\n",
        "        x = self.block_1(x, training=training)\n",
        "        x = self.block_2(x, training=training)\n",
        "        if include_aux_logits and self.aux_logits:\n",
        "            aux = self.AuxLogits(x)\n",
        "        x = self.block_3(x, training=training)\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        if include_aux_logits and self.aux_logits:\n",
        "            return _InceptionOutputs(x, aux)\n",
        "        return x"
      ],
      "metadata": {
        "id": "bBtoxVWEG8CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    model =InceptionV3(num_class=NUM_CLASSES)\n",
        "\n",
        "    model.build(input_shape=(None, image_height, image_width, channels))\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # GPU settings\n",
        "    # gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    # if gpus:\n",
        "    #     for gpu in gpus:\n",
        "    #         tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "    # create model\n",
        "    model = get_model()\n",
        "\n",
        "    # define loss and optimizer\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "    optimizer = tf.keras.optimizers.Adadelta()\n",
        "\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "    valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "    valid_accuracy = tf.keras.metrics.CategoricalAccuracy(name='valid_accuracy')\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(images, labels):\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(images, include_aux_logits=True, training=True)\n",
        "            loss_aux = loss_object(y_true=labels, y_pred=predictions.aux_logits)\n",
        "            loss = 0.5 * loss_aux + 0.5 * loss_object(y_true=labels, y_pred=predictions.logits)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n",
        "\n",
        "        train_loss(loss)\n",
        "        train_accuracy(labels, predictions.logits)\n",
        "\n",
        "    @tf.function\n",
        "    def valid_step(images, labels):\n",
        "        predictions = model(images, include_aux_logits=False, training=False)\n",
        "        v_loss = loss_object(labels, predictions)\n",
        "\n",
        "        valid_loss(v_loss)\n",
        "        valid_accuracy(labels, predictions)\n",
        "\n",
        "    # start training\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss.reset_states()\n",
        "        train_accuracy.reset_states()\n",
        "        valid_loss.reset_states()\n",
        "        valid_accuracy.reset_states()\n",
        "        step = 0\n",
        "        for images, labels in train_generator:\n",
        "            step += 1\n",
        "            train_step(images, labels)\n",
        "            print(\"Epoch: {}/{}, step: {}, loss: {:.5f}, accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                                     EPOCHS,\n",
        "                                                                                     step,\n",
        "                                                                                     train_loss.result(),\n",
        "                                                                                     train_accuracy.result()))\n",
        "\n",
        "        for valid_images, valid_labels in validation_generator:\n",
        "            valid_step(valid_images, valid_labels)\n",
        "\n",
        "        print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\n",
        "              \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch + 1,\n",
        "                                                                  EPOCHS,\n",
        "                                                                  train_loss.result(),\n",
        "                                                                  train_accuracy.result(),\n",
        "                                                                  valid_loss.result(),\n",
        "                                                                  valid_accuracy.result()))\n",
        "\n",
        "    model.save_weights(filepath = save_model_dir, save_format='tf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfCM0NC3J1xZ",
        "outputId": "fd865d04-bf58-4f5e-c693-98e0afaa83b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " preprocess (Preprocess)     multiple                  173872    \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 38, 38, 288)       822896    \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 18, 18, 768)       7997312   \n",
            "                                                                 \n",
            " inception_aux (InceptionAux  multiple                 2563460   \n",
            " )                                                               \n",
            "                                                                 \n",
            " sequential_2 (Sequential)   (None, 8, 8, 2048)        11065984  \n",
            "                                                                 \n",
            " average_pooling2d_6 (Averag  multiple                 0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dropout (Dropout)           multiple                  0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  8196      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,631,720\n",
            "Trainable params: 22,598,568\n",
            "Non-trainable params: 33,152\n",
            "_________________________________________________________________\n",
            "Epoch: 1/20, step: 1, loss: 6.39174, accuracy: 0.18000\n",
            "Epoch: 1/20, step: 2, loss: 6.75682, accuracy: 0.20500\n",
            "Epoch: 1/20, step: 3, loss: 6.55060, accuracy: 0.22333\n",
            "Epoch: 1/20, step: 4, loss: 6.53657, accuracy: 0.22500\n",
            "Epoch: 1/20, step: 5, loss: 6.48781, accuracy: 0.23200\n",
            "Epoch: 1/20, step: 6, loss: 6.57517, accuracy: 0.22500\n",
            "Epoch: 1/20, step: 7, loss: 6.54376, accuracy: 0.23429\n",
            "Epoch: 1/20, step: 8, loss: 6.59955, accuracy: 0.24250\n",
            "Epoch: 1/20, step: 9, loss: 6.59619, accuracy: 0.24333\n",
            "Epoch: 1/20, step: 10, loss: 6.59902, accuracy: 0.24300\n",
            "Epoch: 1/20, step: 11, loss: 6.58691, accuracy: 0.24818\n",
            "Epoch: 1/20, step: 12, loss: 6.54867, accuracy: 0.24167\n",
            "Epoch: 1/20, step: 13, loss: 6.64666, accuracy: 0.23615\n",
            "Epoch: 1/20, step: 14, loss: 6.58958, accuracy: 0.24071\n",
            "Epoch: 1/20, step: 15, loss: 6.58323, accuracy: 0.24333\n",
            "Epoch: 1/20, step: 16, loss: 6.61109, accuracy: 0.24375\n",
            "Epoch: 1/20, step: 17, loss: 6.63762, accuracy: 0.24588\n",
            "Epoch: 1/20, step: 18, loss: 6.58460, accuracy: 0.24500\n",
            "Epoch: 1/20, step: 19, loss: 6.54298, accuracy: 0.24579\n",
            "Epoch: 1/20, step: 20, loss: 6.54345, accuracy: 0.24700\n",
            "Epoch: 1/20, step: 21, loss: 6.50336, accuracy: 0.24667\n",
            "Epoch: 1/20, step: 22, loss: 6.47572, accuracy: 0.24591\n",
            "Epoch: 1/20, step: 23, loss: 6.47108, accuracy: 0.24826\n",
            "Epoch: 1/20, step: 24, loss: 6.45243, accuracy: 0.25125\n",
            "Epoch: 1/20, step: 25, loss: 6.44999, accuracy: 0.24920\n",
            "Epoch: 1/20, step: 26, loss: 6.41635, accuracy: 0.25077\n",
            "Epoch: 1/20, step: 27, loss: 6.43833, accuracy: 0.25259\n",
            "Epoch: 1/20, step: 28, loss: 6.45058, accuracy: 0.25071\n",
            "Epoch: 1/20, step: 29, loss: 6.47173, accuracy: 0.25034\n",
            "Epoch: 1/20, step: 30, loss: 6.45732, accuracy: 0.25000\n",
            "Epoch: 1/20, step: 31, loss: 6.43404, accuracy: 0.24935\n",
            "Epoch: 1/20, step: 32, loss: 6.42234, accuracy: 0.25125\n",
            "Epoch: 1/20, step: 33, loss: 6.41886, accuracy: 0.25030\n",
            "Epoch: 1/20, step: 34, loss: 6.43256, accuracy: 0.25265\n",
            "Epoch: 1/20, step: 35, loss: 6.42918, accuracy: 0.25171\n",
            "Epoch: 1/20, step: 36, loss: 6.41130, accuracy: 0.25194\n",
            "Epoch: 1/20, step: 37, loss: 6.39549, accuracy: 0.25081\n",
            "Epoch: 1/20, step: 38, loss: 6.40470, accuracy: 0.25237\n",
            "Epoch: 1/20, step: 39, loss: 6.38230, accuracy: 0.25205\n",
            "Epoch: 1/20, step: 40, loss: 6.36026, accuracy: 0.24975\n",
            "Epoch: 1/20, step: 41, loss: 6.34623, accuracy: 0.25098\n",
            "Epoch: 1/20, step: 42, loss: 6.37491, accuracy: 0.25214\n",
            "Epoch: 1/20, step: 43, loss: 6.36706, accuracy: 0.25093\n"
          ]
        }
      ]
    }
  ]
}